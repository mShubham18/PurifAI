{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\1745420125.py:1: DtypeWarning: Columns (76) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"dataset.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dabl  # Optional, for ML-based inference\n",
    "\n",
    "def infer_and_convert_dtypes(df):\n",
    "    \"\"\"\n",
    "    Infers column data types and converts them to the best possible types.\n",
    "    Returns the cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    dtype_mapping = {}\n",
    "\n",
    "    for col in df.columns:\n",
    "        inferred = pd.api.types.infer_dtype(df[col])\n",
    "\n",
    "        if inferred in ['integer', 'floating']:\n",
    "            dtype_mapping[col] = df[col].dtype  # Keep as numeric\n",
    "        elif inferred in ['boolean']:\n",
    "            dtype_mapping[col] = 'boolean'\n",
    "        elif inferred in ['datetime']:\n",
    "            dtype_mapping[col] = 'datetime64[ns]'\n",
    "        elif inferred in ['string', 'unicode']:\n",
    "            dtype_mapping[col] = 'string'\n",
    "        elif inferred in ['mixed', 'categorical']:\n",
    "            dtype_mapping[col] = 'category'\n",
    "        else:\n",
    "            dtype_mapping[col] = 'object'  # Default to object\n",
    "\n",
    "    # Apply inferred data types\n",
    "    for col, dtype in dtype_mapping.items():\n",
    "        try:\n",
    "            df[col] = df[col].astype(dtype)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Couldn't convert {col} to {dtype}. Error: {e}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18979 entries, 0 to 18978\n",
      "Data columns (total 77 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   photoUrl          18979 non-null  string\n",
      " 1   LongName          18979 non-null  string\n",
      " 2   playerUrl         18979 non-null  string\n",
      " 3   Nationality       18979 non-null  string\n",
      " 4   Positions         18979 non-null  string\n",
      " 5   Name              18979 non-null  string\n",
      " 6   Age               18979 non-null  Int64 \n",
      " 7   ↓OVA              18979 non-null  Int64 \n",
      " 8   POT               18979 non-null  Int64 \n",
      " 9   Team & Contract   18979 non-null  string\n",
      " 10  ID                18979 non-null  Int64 \n",
      " 11  Height            18979 non-null  string\n",
      " 12  Weight            18979 non-null  string\n",
      " 13  foot              18979 non-null  string\n",
      " 14  BOV               18979 non-null  Int64 \n",
      " 15  BP                18979 non-null  string\n",
      " 16  Growth            18979 non-null  Int64 \n",
      " 17  Joined            18979 non-null  string\n",
      " 18  Loan Date End     1013 non-null   string\n",
      " 19  Value             18979 non-null  string\n",
      " 20  Wage              18979 non-null  string\n",
      " 21  Release Clause    18979 non-null  string\n",
      " 22  Attacking         18979 non-null  Int64 \n",
      " 23  Crossing          18979 non-null  Int64 \n",
      " 24  Finishing         18979 non-null  Int64 \n",
      " 25  Heading Accuracy  18979 non-null  Int64 \n",
      " 26  Short Passing     18979 non-null  Int64 \n",
      " 27  Volleys           18979 non-null  Int64 \n",
      " 28  Skill             18979 non-null  Int64 \n",
      " 29  Dribbling         18979 non-null  Int64 \n",
      " 30  Curve             18979 non-null  Int64 \n",
      " 31  FK Accuracy       18979 non-null  Int64 \n",
      " 32  Long Passing      18979 non-null  Int64 \n",
      " 33  Ball Control      18979 non-null  Int64 \n",
      " 34  Movement          18979 non-null  Int64 \n",
      " 35  Acceleration      18979 non-null  Int64 \n",
      " 36  Sprint Speed      18979 non-null  Int64 \n",
      " 37  Agility           18979 non-null  Int64 \n",
      " 38  Reactions         18979 non-null  Int64 \n",
      " 39  Balance           18979 non-null  Int64 \n",
      " 40  Power             18979 non-null  Int64 \n",
      " 41  Shot Power        18979 non-null  Int64 \n",
      " 42  Jumping           18979 non-null  Int64 \n",
      " 43  Stamina           18979 non-null  Int64 \n",
      " 44  Strength          18979 non-null  Int64 \n",
      " 45  Long Shots        18979 non-null  Int64 \n",
      " 46  Mentality         18979 non-null  Int64 \n",
      " 47  Aggression        18979 non-null  Int64 \n",
      " 48  Interceptions     18979 non-null  Int64 \n",
      " 49  Positioning       18979 non-null  Int64 \n",
      " 50  Vision            18979 non-null  Int64 \n",
      " 51  Penalties         18979 non-null  Int64 \n",
      " 52  Composure         18979 non-null  Int64 \n",
      " 53  Defending         18979 non-null  Int64 \n",
      " 54  Marking           18979 non-null  Int64 \n",
      " 55  Standing Tackle   18979 non-null  Int64 \n",
      " 56  Sliding Tackle    18979 non-null  Int64 \n",
      " 57  Goalkeeping       18979 non-null  Int64 \n",
      " 58  GK Diving         18979 non-null  Int64 \n",
      " 59  GK Handling       18979 non-null  Int64 \n",
      " 60  GK Kicking        18979 non-null  Int64 \n",
      " 61  GK Positioning    18979 non-null  Int64 \n",
      " 62  GK Reflexes       18979 non-null  Int64 \n",
      " 63  Total Stats       18979 non-null  Int64 \n",
      " 64  Base Stats        18979 non-null  Int64 \n",
      " 65  W/F               18979 non-null  string\n",
      " 66  SM                18979 non-null  string\n",
      " 67  A/W               18979 non-null  string\n",
      " 68  D/W               18979 non-null  string\n",
      " 69  IR                18979 non-null  string\n",
      " 70  PAC               18979 non-null  Int64 \n",
      " 71  SHO               18979 non-null  Int64 \n",
      " 72  PAS               18979 non-null  Int64 \n",
      " 73  DRI               18979 non-null  Int64 \n",
      " 74  DEF               18979 non-null  Int64 \n",
      " 75  PHY               18979 non-null  Int64 \n",
      " 76  Hits              18979 non-null  object\n",
      "dtypes: Int64(55), object(1), string(21)\n",
      "memory usage: 12.1+ MB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\1026067717.py:4: DtypeWarning: Columns (76) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"dataset.csv\")\n",
      "c:\\Users\\HP\\OneDrive\\Documents\\PurifAI\\purifai\\Lib\\site-packages\\dabl\\preprocessing.py:177: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(series[:10])\n",
      "c:\\Users\\HP\\OneDrive\\Documents\\PurifAI\\purifai\\Lib\\site-packages\\dabl\\preprocessing.py:177: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(series[:10])\n",
      "c:\\Users\\HP\\OneDrive\\Documents\\PurifAI\\purifai\\Lib\\site-packages\\dabl\\preprocessing.py:177: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(series[:10])\n",
      "c:\\Users\\HP\\OneDrive\\Documents\\PurifAI\\purifai\\Lib\\site-packages\\dabl\\preprocessing.py:177: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(series[:10])\n",
      "c:\\Users\\HP\\OneDrive\\Documents\\PurifAI\\purifai\\Lib\\site-packages\\dabl\\preprocessing.py:177: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(series[:10])\n",
      "c:\\Users\\HP\\OneDrive\\Documents\\PurifAI\\purifai\\Lib\\site-packages\\dabl\\preprocessing.py:177: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(series[:10])\n",
      "c:\\Users\\HP\\OneDrive\\Documents\\PurifAI\\purifai\\Lib\\site-packages\\dabl\\preprocessing.py:177: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(series[:10])\n",
      "c:\\Users\\HP\\OneDrive\\Documents\\PurifAI\\purifai\\Lib\\site-packages\\dabl\\preprocessing.py:177: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(series[:10])\n",
      "c:\\Users\\HP\\OneDrive\\Documents\\PurifAI\\purifai\\Lib\\site-packages\\dabl\\preprocessing.py:177: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(series[:10])\n",
      "c:\\Users\\HP\\OneDrive\\Documents\\PurifAI\\purifai\\Lib\\site-packages\\dabl\\preprocessing.py:177: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(series[:10])\n",
      "c:\\Users\\HP\\OneDrive\\Documents\\PurifAI\\purifai\\Lib\\site-packages\\dabl\\preprocessing.py:177: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(series[:10])\n",
      "c:\\Users\\HP\\OneDrive\\Documents\\PurifAI\\purifai\\Lib\\site-packages\\dabl\\preprocessing.py:177: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(series[:10])\n",
      "c:\\Users\\HP\\OneDrive\\Documents\\PurifAI\\purifai\\Lib\\site-packages\\dabl\\preprocessing.py:177: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(series[:10])\n",
      "c:\\Users\\HP\\OneDrive\\Documents\\PurifAI\\purifai\\Lib\\site-packages\\dabl\\preprocessing.py:177: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(series[:10])\n",
      "c:\\Users\\HP\\OneDrive\\Documents\\PurifAI\\purifai\\Lib\\site-packages\\dabl\\preprocessing.py:177: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(series[:10])\n",
      "c:\\Users\\HP\\OneDrive\\Documents\\PurifAI\\purifai\\Lib\\site-packages\\dabl\\preprocessing.py:177: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(series[:10])\n",
      "c:\\Users\\HP\\OneDrive\\Documents\\PurifAI\\purifai\\Lib\\site-packages\\dabl\\preprocessing.py:177: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(series[:10])\n",
      "c:\\Users\\HP\\OneDrive\\Documents\\PurifAI\\purifai\\Lib\\site-packages\\dabl\\preprocessing.py:177: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(series[:10])\n",
      "c:\\Users\\HP\\OneDrive\\Documents\\PurifAI\\purifai\\Lib\\site-packages\\dabl\\preprocessing.py:177: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pd.to_datetime(series[:10])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>continuous</th>\n",
       "      <th>dirty_float</th>\n",
       "      <th>low_card_int_ordinal</th>\n",
       "      <th>low_card_int_categorical</th>\n",
       "      <th>categorical</th>\n",
       "      <th>date</th>\n",
       "      <th>free_string</th>\n",
       "      <th>useless</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>photoUrl</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LongName</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>playerUrl</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nationality</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positions</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAS</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRI</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEF</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PHY</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hits</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             continuous  dirty_float  low_card_int_ordinal  \\\n",
       "photoUrl          False        False                 False   \n",
       "LongName          False        False                 False   \n",
       "playerUrl         False        False                 False   \n",
       "Nationality       False        False                 False   \n",
       "Positions         False        False                 False   \n",
       "...                 ...          ...                   ...   \n",
       "PAS               False        False                  True   \n",
       "DRI               False        False                  True   \n",
       "DEF               False        False                  True   \n",
       "PHY               False        False                  True   \n",
       "Hits              False        False                 False   \n",
       "\n",
       "             low_card_int_categorical  categorical   date  free_string  \\\n",
       "photoUrl                        False        False  False         True   \n",
       "LongName                        False        False  False         True   \n",
       "playerUrl                       False        False  False         True   \n",
       "Nationality                     False         True  False        False   \n",
       "Positions                       False        False  False         True   \n",
       "...                               ...          ...    ...          ...   \n",
       "PAS                             False        False  False        False   \n",
       "DRI                             False        False  False        False   \n",
       "DEF                             False        False  False        False   \n",
       "PHY                             False        False  False        False   \n",
       "Hits                            False        False  False         True   \n",
       "\n",
       "             useless  \n",
       "photoUrl       False  \n",
       "LongName       False  \n",
       "playerUrl      False  \n",
       "Nationality    False  \n",
       "Positions      False  \n",
       "...              ...  \n",
       "PAS            False  \n",
       "DRI            False  \n",
       "DEF            False  \n",
       "PHY            False  \n",
       "Hits           False  \n",
       "\n",
       "[77 rows x 8 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dabl  # Auto-infers column types\n",
    "\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "df_cleaned = dabl.detect_types(df)  # Automatically detects column types\n",
    "\n",
    "df_cleaned # Shows inferred types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "photoUrl       datetime64[ns]\n",
      "LongName       datetime64[ns]\n",
      "playerUrl      datetime64[ns]\n",
      "Nationality    datetime64[ns]\n",
      "Positions      datetime64[ns]\n",
      "                    ...      \n",
      "PAS            datetime64[ns]\n",
      "DRI            datetime64[ns]\n",
      "DEF            datetime64[ns]\n",
      "PHY            datetime64[ns]\n",
      "Hits           datetime64[ns]\n",
      "Length: 77, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset safely\n",
    "df = pd.read_csv(\"dataset.csv\", low_memory=False)\n",
    "\n",
    "# Step 1: Ensure numeric columns are properly detected\n",
    "df = df.convert_dtypes()\n",
    "\n",
    "# Step 2: Explicitly handle datetime columns\n",
    "for col in df.columns:\n",
    "    try:\n",
    "        # Convert columns that look like dates\n",
    "        df[col] = pd.to_datetime(df[col], format=\"%Y-%m-%d\", errors=\"coerce\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Step 3: Check final column types\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2368985367.py:12: DtypeWarning: Columns (76) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Encoders require their input argument must be uniformly strings or numbers. Got ['int', 'str']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\OneDrive\\Documents\\PurifAI\\purifai\\Lib\\site-packages\\sklearn\\utils\\_encode.py:183\u001b[39m, in \u001b[36m_unique_python\u001b[39m\u001b[34m(values, return_inverse, return_counts)\u001b[39m\n\u001b[32m    181\u001b[39m uniques_set, missing_values = _extract_missing(uniques_set)\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m uniques = \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43muniques_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m uniques.extend(missing_values.to_list())\n",
      "\u001b[31mTypeError\u001b[39m: '<' not supported between instances of 'int' and 'str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[118]\u001b[39m\u001b[32m, line 68\u001b[39m\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m cleaned_df = \u001b[43mclean_and_engineer_data\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdataset.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[38;5;28mprint\u001b[39m(cleaned_df.head())\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[118]\u001b[39m\u001b[32m, line 50\u001b[39m, in \u001b[36mclean_and_engineer_data\u001b[39m\u001b[34m(file_path)\u001b[39m\n\u001b[32m     47\u001b[39m categorical_cols = df.select_dtypes(include=[\u001b[33m'\u001b[39m\u001b[33mobject\u001b[39m\u001b[33m'\u001b[39m]).columns\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(categorical_cols) > \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     encoded_array = \u001b[43mencoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcategorical_cols\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     encoded_df = pd.DataFrame(encoded_array, columns=encoder.get_feature_names_out(categorical_cols))\n\u001b[32m     53\u001b[39m     \u001b[38;5;66;03m# Keep only the original categorical columns, replacing them with their encoded versions\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\OneDrive\\Documents\\PurifAI\\purifai\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m         return_tuple = (\n\u001b[32m    323\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    324\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    325\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\OneDrive\\Documents\\PurifAI\\purifai\\Lib\\site-packages\\sklearn\\base.py:918\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    903\u001b[39m         warnings.warn(\n\u001b[32m    904\u001b[39m             (\n\u001b[32m    905\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) has a `transform`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    913\u001b[39m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    914\u001b[39m         )\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    917\u001b[39m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m.transform(X)\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    920\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\OneDrive\\Documents\\PurifAI\\purifai\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\OneDrive\\Documents\\PurifAI\\purifai\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:991\u001b[39m, in \u001b[36mOneHotEncoder.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    972\u001b[39m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    973\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    974\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    975\u001b[39m \u001b[33;03m    Fit OneHotEncoder to X.\u001b[39;00m\n\u001b[32m    976\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    989\u001b[39m \u001b[33;03m        Fitted encoder.\u001b[39;00m\n\u001b[32m    990\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m991\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    992\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    993\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    994\u001b[39m \u001b[43m        \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    995\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    996\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_drop_idx()\n\u001b[32m    997\u001b[39m     \u001b[38;5;28mself\u001b[39m._n_features_outs = \u001b[38;5;28mself\u001b[39m._compute_n_features_outs()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\OneDrive\\Documents\\PurifAI\\purifai\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:103\u001b[39m, in \u001b[36m_BaseEncoder._fit\u001b[39m\u001b[34m(self, X, handle_unknown, ensure_all_finite, return_counts, return_and_ignore_missing_for_infrequent)\u001b[39m\n\u001b[32m    100\u001b[39m Xi = X_list[i]\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.categories == \u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     result = \u001b[43m_unique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompute_counts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m compute_counts:\n\u001b[32m    105\u001b[39m         cats, counts = result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\OneDrive\\Documents\\PurifAI\\purifai\\Lib\\site-packages\\sklearn\\utils\\_encode.py:52\u001b[39m, in \u001b[36m_unique\u001b[39m\u001b[34m(values, return_inverse, return_counts)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Helper function to find unique values with support for python objects.\u001b[39;00m\n\u001b[32m     22\u001b[39m \n\u001b[32m     23\u001b[39m \u001b[33;03mUses pure python method for object dtype, and numpy method for\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     49\u001b[39m \u001b[33;03m    array. Only provided if `return_counts` is True.\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m values.dtype == \u001b[38;5;28mobject\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_unique_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_counts\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# numerical\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _unique_np(\n\u001b[32m     57\u001b[39m     values, return_inverse=return_inverse, return_counts=return_counts\n\u001b[32m     58\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\OneDrive\\Documents\\PurifAI\\purifai\\Lib\\site-packages\\sklearn\\utils\\_encode.py:188\u001b[39m, in \u001b[36m_unique_python\u001b[39m\u001b[34m(values, return_inverse, return_counts)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    187\u001b[39m     types = \u001b[38;5;28msorted\u001b[39m(t.\u001b[34m__qualname__\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mtype\u001b[39m(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values))\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    189\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mEncoders require their input argument must be uniformly \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    190\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mstrings or numbers. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    191\u001b[39m     )\n\u001b[32m    192\u001b[39m ret = (uniques,)\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_inverse:\n",
      "\u001b[31mTypeError\u001b[39m: Encoders require their input argument must be uniformly strings or numbers. Got ['int', 'str']"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy import stats\n",
    "\n",
    "def clean_and_engineer_data(file_path):\n",
    "    \"\"\" Fully automates data cleaning & feature engineering, keeping only original columns \"\"\"\n",
    "\n",
    "    # Load data\n",
    "    if file_path.endswith('.csv'):\n",
    "        df = pd.read_csv(file_path)\n",
    "    elif file_path.endswith('.xlsx'):\n",
    "        df = pd.read_excel(file_path)\n",
    "    elif file_path.endswith('.json'):\n",
    "        df = pd.read_json(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Use CSV, Excel, or JSON.\")\n",
    "\n",
    "    # Backup original column names\n",
    "    original_columns = df.columns.tolist()\n",
    "\n",
    "    # Drop duplicates\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Handle missing values (numeric → mean, categorical → most frequent)\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':  # Categorical\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])\n",
    "        else:  # Numeric\n",
    "            df[col] = df[col].fillna(df[col].mean())\n",
    "\n",
    "    # Remove outliers using IQR\n",
    "    def remove_outliers(df):\n",
    "        num_cols = df.select_dtypes(include=np.number).columns\n",
    "        for col in num_cols:\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            df = df[(df[col] >= Q1 - 1.5 * IQR) & (df[col] <= Q3 + 1.5 * IQR)]\n",
    "        return df\n",
    "\n",
    "    df = remove_outliers(df)\n",
    "\n",
    "    # Encode categorical variables (but keep original format)\n",
    "    encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "    if len(categorical_cols) > 0:\n",
    "        encoded_array = encoder.fit_transform(df[categorical_cols])\n",
    "        encoded_df = pd.DataFrame(encoded_array, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "        \n",
    "        # Keep only the original categorical columns, replacing them with their encoded versions\n",
    "        df = df.drop(columns=categorical_cols)\n",
    "        df[encoded_df.columns] = encoded_df\n",
    "\n",
    "    # Scale numerical columns if needed\n",
    "    num_cols = df.select_dtypes(include=np.number).columns\n",
    "    scaler = StandardScaler()\n",
    "    df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "\n",
    "    # Restore original column names\n",
    "    df.columns = original_columns\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "cleaned_df = clean_and_engineer_data(\"dataset.csv\")\n",
    "print(cleaned_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\547523651.py:3: DtypeWarning: Columns (76) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(\"dataset.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 12564 entries, 146 to 18962\n",
      "Data columns (total 77 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   photourl          12564 non-null  object\n",
      " 1   longname          12564 non-null  object\n",
      " 2   playerurl         12564 non-null  object\n",
      " 3   nationality       12564 non-null  object\n",
      " 4   positions         12564 non-null  object\n",
      " 5   name              12564 non-null  object\n",
      " 6   age               12564 non-null  int64 \n",
      " 7   ↓ova              12564 non-null  int64 \n",
      " 8   pot               12564 non-null  int64 \n",
      " 9   team & contract   12564 non-null  object\n",
      " 10  id                12564 non-null  int64 \n",
      " 11  height            12564 non-null  object\n",
      " 12  weight            12564 non-null  object\n",
      " 13  foot              12564 non-null  object\n",
      " 14  bov               12564 non-null  int64 \n",
      " 15  bp                12564 non-null  object\n",
      " 16  growth            12564 non-null  int64 \n",
      " 17  joined            12564 non-null  object\n",
      " 18  loan date end     12564 non-null  object\n",
      " 19  value             12564 non-null  object\n",
      " 20  wage              12564 non-null  object\n",
      " 21  release clause    12564 non-null  object\n",
      " 22  attacking         12564 non-null  int64 \n",
      " 23  crossing          12564 non-null  int64 \n",
      " 24  finishing         12564 non-null  int64 \n",
      " 25  heading accuracy  12564 non-null  int64 \n",
      " 26  short passing     12564 non-null  int64 \n",
      " 27  volleys           12564 non-null  int64 \n",
      " 28  skill             12564 non-null  int64 \n",
      " 29  dribbling         12564 non-null  int64 \n",
      " 30  curve             12564 non-null  int64 \n",
      " 31  fk accuracy       12564 non-null  int64 \n",
      " 32  long passing      12564 non-null  int64 \n",
      " 33  ball control      12564 non-null  int64 \n",
      " 34  movement          12564 non-null  int64 \n",
      " 35  acceleration      12564 non-null  int64 \n",
      " 36  sprint speed      12564 non-null  int64 \n",
      " 37  agility           12564 non-null  int64 \n",
      " 38  reactions         12564 non-null  int64 \n",
      " 39  balance           12564 non-null  int64 \n",
      " 40  power             12564 non-null  int64 \n",
      " 41  shot power        12564 non-null  int64 \n",
      " 42  jumping           12564 non-null  int64 \n",
      " 43  stamina           12564 non-null  int64 \n",
      " 44  strength          12564 non-null  int64 \n",
      " 45  long shots        12564 non-null  int64 \n",
      " 46  mentality         12564 non-null  int64 \n",
      " 47  aggression        12564 non-null  int64 \n",
      " 48  interceptions     12564 non-null  int64 \n",
      " 49  positioning       12564 non-null  int64 \n",
      " 50  vision            12564 non-null  int64 \n",
      " 51  penalties         12564 non-null  int64 \n",
      " 52  composure         12564 non-null  int64 \n",
      " 53  defending         12564 non-null  int64 \n",
      " 54  marking           12564 non-null  int64 \n",
      " 55  standing tackle   12564 non-null  int64 \n",
      " 56  sliding tackle    12564 non-null  int64 \n",
      " 57  goalkeeping       12564 non-null  int64 \n",
      " 58  gk diving         12564 non-null  int64 \n",
      " 59  gk handling       12564 non-null  int64 \n",
      " 60  gk kicking        12564 non-null  int64 \n",
      " 61  gk positioning    12564 non-null  int64 \n",
      " 62  gk reflexes       12564 non-null  int64 \n",
      " 63  total stats       12564 non-null  int64 \n",
      " 64  base stats        12564 non-null  int64 \n",
      " 65  w/f               12564 non-null  object\n",
      " 66  sm                12564 non-null  object\n",
      " 67  a/w               12564 non-null  object\n",
      " 68  d/w               12564 non-null  object\n",
      " 69  ir                12564 non-null  object\n",
      " 70  pac               12564 non-null  int64 \n",
      " 71  sho               12564 non-null  int64 \n",
      " 72  pas               12564 non-null  int64 \n",
      " 73  dri               12564 non-null  int64 \n",
      " 74  def               12564 non-null  int64 \n",
      " 75  phy               12564 non-null  int64 \n",
      " 76  hits              12564 non-null  object\n",
      "dtypes: int64(55), object(22)\n",
      "memory usage: 7.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv(\"dataset.csv\")\n",
    "def clean_data(file_path):\n",
    "    \"\"\"Cleans messy dataset: fixes datatypes, fills missing values, removes outliers.\"\"\"\n",
    "    \n",
    "    # Load dataset efficiently\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, low_memory=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Drop duplicates & completely empty columns\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "\n",
    "    # Convert column names to lowercase & remove leading/trailing spaces\n",
    "    df.columns = df.columns.str.lower().str.strip()\n",
    "\n",
    "    # Detect and fix incorrect data types\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].apply(lambda x: np.nan if str(x).strip().lower() in [\"nan\", \"none\", \"null\", \"n/a\", \"\"] else x)\n",
    "\n",
    "        if df[col].dtype == 'object':  # If it's a string column\n",
    "            try:\n",
    "                df[col] = pd.to_numeric(df[col])  # Try converting to numeric\n",
    "            except:\n",
    "                pass  # If it fails, keep it as a categorical/text column\n",
    "\n",
    "    # Fill missing values intelligently\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype in ['int64', 'float64']:  # Numeric columns\n",
    "            df[col] = df[col].fillna(df[col].median())  # Use median for robustness\n",
    "        else:  # Categorical columns\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])  # Use most common value\n",
    "\n",
    "    # Handle outliers using IQR method (more robust than standard deviation)\n",
    "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    for col in numeric_cols:\n",
    "        Q1, Q3 = df[col].quantile(0.25), df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound, upper_bound = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\n",
    "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "\n",
    "    # Convert categorical columns to proper string type\n",
    "    cat_cols = df.select_dtypes(include=['object']).columns\n",
    "    df[cat_cols] = df[cat_cols].astype(str)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "cleaned_df = clean_data(\"dataset.csv\")\n",
    "print(cleaned_df.info())  # Check final datatypes\n",
    " # Preview cleaned data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DFSHAPE: (18979, 77)\n",
      "NEWDF SHAPE: (12564, 77)\n"
     ]
    }
   ],
   "source": [
    "print(f\"DFSHAPE: {df.shape}\")\n",
    "print(f\"NEWDF SHAPE: {cleaned_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "def data_standardization(df):\n",
    "    \"\"\"\n",
    "    Standardizes the cleaned dataframe by performing:\n",
    "    - Column name formatting\n",
    "    - String standardization (trim spaces, lowercase)\n",
    "    - Duplicate removal\n",
    "    - Handling incorrect values\n",
    "    - Converting data types (dates, numerics, categories)\n",
    "    - Feature engineering & outlier handling\n",
    "    \"\"\"\n",
    "\n",
    "    # 1️⃣ Standardize Column Names\n",
    "    df.columns = df.columns.str.lower().str.strip().str.replace(' ', '_')\n",
    "\n",
    "    # 2️⃣ Trim Spaces & Convert Strings to Lowercase\n",
    "    df = df.applymap(lambda x: x.strip().lower() if isinstance(x, str) else x)\n",
    "\n",
    "    # 3️⃣ Convert Dates to Standard Format\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        try:\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce')  # Convert date columns\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # 4️⃣ Handle Missing Values\n",
    "    for col in df.columns:\n",
    "        if df[col].isnull().sum() / len(df) > 0.8:  # Drop columns with >80% missing\n",
    "            df.drop(columns=[col], inplace=True)\n",
    "        elif df[col].dtype == 'object':\n",
    "            df[col].fillna(df[col].mode()[0], inplace=True)  # Fill categorical with mode\n",
    "        else:\n",
    "            df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
    "\n",
    "    # 5️⃣ Remove Duplicates\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    # 6️⃣ Fix Inconsistent Categorical Values\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df[col] = df[col].str.replace(r'[^a-zA-Z0-9\\s]', '', regex=True)  # Remove special chars\n",
    "\n",
    "    # 7️⃣ Handle Outliers with Winsorization\n",
    "    for col in df.select_dtypes(include=['int64', 'float64']).columns:\n",
    "        df[col] = winsorize(df[col], limits=[0.05, 0.05])  # Clip extreme 5% values\n",
    "\n",
    "    # 8️⃣ Feature Engineering: Extract Year if Date Exists\n",
    "    date_cols = df.select_dtypes(include=['datetime64']).columns\n",
    "    for col in date_cols:\n",
    "        df[f\"{col}_year\"] = df[col].dt.year\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:21: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.strip().lower() if isinstance(x, str) else x)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:26: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')  # Convert date columns\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:26: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')  # Convert date columns\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:26: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')  # Convert date columns\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:26: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')  # Convert date columns\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:26: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')  # Convert date columns\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:26: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')  # Convert date columns\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:26: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')  # Convert date columns\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:26: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')  # Convert date columns\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:26: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')  # Convert date columns\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:26: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')  # Convert date columns\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:26: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')  # Convert date columns\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:26: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')  # Convert date columns\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:26: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')  # Convert date columns\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:26: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')  # Convert date columns\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:26: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')  # Convert date columns\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:26: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')  # Convert date columns\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:26: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')  # Convert date columns\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:26: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')  # Convert date columns\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:26: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')  # Convert date columns\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:26: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')  # Convert date columns\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:26: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')  # Convert date columns\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:26: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], errors='coerce')  # Convert date columns\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2088059554.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)  # Fill numerical with median\n"
     ]
    }
   ],
   "source": [
    "standardized_data = data_standardization(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12564, 59)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def clean_and_standardize_data(file_path):\n",
    "    # Load dataset\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Remove duplicate rows\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    # Replace string \"nan\" with actual NaN values\n",
    "    df.replace(\"nan\", np.nan, inplace=True)\n",
    "    \n",
    "    # Handling missing values\n",
    "    for col in df.columns:\n",
    "        if df[col].isna().sum() / len(df) > 0.6:\n",
    "            df.drop(columns=[col], inplace=True)  # Drop columns with more than 60% missing values\n",
    "        elif df[col].dtype in ['int64', 'float64']:\n",
    "            imputer = SimpleImputer(strategy='median')  # Fill numeric columns with median\n",
    "            df[col] = imputer.fit_transform(df[[col]])\n",
    "        else:\n",
    "            imputer = SimpleImputer(strategy='most_frequent')  # Fill categorical columns with mode\n",
    "            df[col] = imputer.fit_transform(df[[col]])\n",
    "    \n",
    "    # Drop low variance columns (almost all values the same)\n",
    "    for col in df.select_dtypes(include=['int64', 'float64']).columns:\n",
    "        if df[col].nunique() / len(df) < 0.01:\n",
    "            df.drop(columns=[col], inplace=True)\n",
    "    \n",
    "    # Drop highly correlated columns (above 0.95 correlation)\n",
    "    corr_matrix = df.corr()\n",
    "    upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > 0.95)]\n",
    "    df.drop(columns=to_drop, inplace=True)\n",
    "    \n",
    "    # Standardization (applies only to numeric columns)\n",
    "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    scaler = StandardScaler()\n",
    "    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\3616696370.py:44: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[text_cols] = df[text_cols].applymap(remove_special_chars)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   photourl                       longname  \\\n",
      "146  httpscdnsofifacomplayers23048121_60png  Ronaldo Jailson Cabrais Petri   \n",
      "150  httpscdnsofifacomplayers22792821_60png           Nélson Cabral Semedo   \n",
      "158  httpscdnsofifacomplayers21969321_60png      Diego Carlos Santos Silva   \n",
      "161  httpscdnsofifacomplayers21533321_60png                   Duván Zapata   \n",
      "165  httpscdnsofifacomplayers21051421_60png      João Pedro Cavaco Cancelo   \n",
      "\n",
      "                                             playerurl nationality positions  \\\n",
      "146  httpsofifacomplayer230481ronaldojailsoncabrais...      Brazil    CAM RM   \n",
      "150  httpsofifacomplayer227928nelsoncabralsemedo210005    Portugal        RB   \n",
      "158  httpsofifacomplayer219693diegocarlossantossilv...      Brazil        CB   \n",
      "161         httpsofifacomplayer215333duvanzapata210005    Colombia        ST   \n",
      "165  httpsofifacomplayer210514joaopedrocavacocancel...    Portugal        RB   \n",
      "\n",
      "                name       age      ↓ova       pot  \\\n",
      "146  Ronaldo Cabrais  0.707271  2.695886  1.991996   \n",
      "150    Nélson Semedo  0.240157  2.695886  2.512848   \n",
      "158     Diego Carlos  0.473714  2.695886  2.339230   \n",
      "161         D Zapata  0.940828  2.695886  1.991996   \n",
      "165     João Cancelo  0.240157  2.695886  2.512848   \n",
      "\n",
      "                                     team & contract  ...  gk kicking  \\\n",
      "146                   \\n\\n\\n\\nGrêmio\\n2019  2023\\n\\n  ...    0.855919   \n",
      "150  \\n\\n\\n\\nWolverhampton Wanderers\\n2020  2023\\n\\n  ...   -0.145580   \n",
      "158               \\n\\n\\n\\nSevilla FC\\n2019  2024\\n\\n  ...    1.189752   \n",
      "161                 \\n\\n\\n\\nAtalanta\\n2020  2023\\n\\n  ...   -0.813247   \n",
      "165          \\n\\n\\n\\nManchester City\\n2019  2025\\n\\n  ...    1.523585   \n",
      "\n",
      "    gk positioning gk reflexes w/f sm     a/w     d/w  ir       phy   hits  \n",
      "146       1.529848    0.875983  4   4  Medium     Low  1   0.834725   \\n46  \n",
      "150       1.194438    0.539361  3   4  Medium    High  2   1.286938  \\n137  \n",
      "158      -1.153433    0.202739  4   3  Medium    High  2   2.078310  \\n170  \n",
      "161      -1.488843   -0.807126  4   3    High  Medium  2   2.078310  \\n123  \n",
      "165       1.194438    1.212604  3   4    High  Medium  2   0.608619  \\n117  \n",
      "\n",
      "[5 rows x 65 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def remove_special_chars(text):\n",
    "    \"\"\"Removes special symbols, emojis, and unnecessary characters from text.\"\"\"\n",
    "    if isinstance(text, str):\n",
    "        return re.sub(r\"[^\\w\\s]\", \"\", text)  # Keeps only letters, numbers, and spaces\n",
    "    return text\n",
    "\n",
    "def clean_and_standardize_data(file_path, corr_threshold=0.9):\n",
    "    \"\"\"\n",
    "    Cleans messy dataset: fixes datatypes, fills missing values, removes outliers,\n",
    "    drops highly correlated columns, removes special symbols, and standardizes numerical features.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load dataset\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, low_memory=False)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Drop duplicates & completely empty columns\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "\n",
    "    # Convert column names to lowercase & remove leading/trailing spaces\n",
    "    df.columns = df.columns.str.lower().str.strip()\n",
    "\n",
    "    # Detect and fix incorrect data types\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].apply(lambda x: np.nan if str(x).strip().lower() in [\"nan\", \"none\", \"null\", \"n/a\", \"\"] else x)\n",
    "\n",
    "        if df[col].dtype == 'object':  # If it's a string column\n",
    "            try:\n",
    "                df[col] = pd.to_numeric(df[col])  # Try converting to numeric\n",
    "            except:\n",
    "                pass  # If it fails, keep it as a categorical/text column\n",
    "\n",
    "    # Remove special symbols & emojis from text columns\n",
    "    text_cols = df.select_dtypes(include=['object']).columns\n",
    "    df[text_cols] = df[text_cols].applymap(remove_special_chars)\n",
    "\n",
    "    # Fill missing values intelligently\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype in ['int64', 'float64']:  # Numeric columns\n",
    "            df[col] = df[col].fillna(df[col].median())  # Use median for robustness\n",
    "        else:  # Categorical columns\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])  # Use most common value\n",
    "\n",
    "    # Handle outliers using IQR method\n",
    "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    for col in numeric_cols:\n",
    "        Q1, Q3 = df[col].quantile(0.25), df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound, upper_bound = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\n",
    "        df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "\n",
    "    # Drop highly correlated features\n",
    "    corr_matrix = df[numeric_cols].corr().abs()\n",
    "    upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    drop_cols = [column for column in upper_triangle.columns if any(upper_triangle[column] > corr_threshold)]\n",
    "    df = df.drop(columns=drop_cols)\n",
    "\n",
    "    # ✅ Recalculate numeric_cols after dropping correlated features\n",
    "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "    # Standardize numerical columns\n",
    "    scaler = StandardScaler()\n",
    "    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Example usage\n",
    "file_path = \"dataset.csv\"\n",
    "cleaned_standardized_df = clean_and_standardize_data(file_path)\n",
    "\n",
    "print(cleaned_standardized_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photourl</th>\n",
       "      <th>longname</th>\n",
       "      <th>playerurl</th>\n",
       "      <th>nationality</th>\n",
       "      <th>positions</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>↓ova</th>\n",
       "      <th>pot</th>\n",
       "      <th>team &amp; contract</th>\n",
       "      <th>...</th>\n",
       "      <th>gk kicking</th>\n",
       "      <th>gk positioning</th>\n",
       "      <th>gk reflexes</th>\n",
       "      <th>w/f</th>\n",
       "      <th>sm</th>\n",
       "      <th>a/w</th>\n",
       "      <th>d/w</th>\n",
       "      <th>ir</th>\n",
       "      <th>phy</th>\n",
       "      <th>hits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>httpscdnsofifacomplayers23048121_60png</td>\n",
       "      <td>Ronaldo Jailson Cabrais Petri</td>\n",
       "      <td>httpsofifacomplayer230481ronaldojailsoncabrais...</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>CAM RM</td>\n",
       "      <td>Ronaldo Cabrais</td>\n",
       "      <td>0.707271</td>\n",
       "      <td>2.695886</td>\n",
       "      <td>1.991996</td>\n",
       "      <td>\\n\\n\\n\\nGrêmio\\n2019  2023\\n\\n</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855919</td>\n",
       "      <td>1.529848</td>\n",
       "      <td>0.875983</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>0.834725</td>\n",
       "      <td>\\n46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>httpscdnsofifacomplayers22792821_60png</td>\n",
       "      <td>Nélson Cabral Semedo</td>\n",
       "      <td>httpsofifacomplayer227928nelsoncabralsemedo210005</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>RB</td>\n",
       "      <td>Nélson Semedo</td>\n",
       "      <td>0.240157</td>\n",
       "      <td>2.695886</td>\n",
       "      <td>2.512848</td>\n",
       "      <td>\\n\\n\\n\\nWolverhampton Wanderers\\n2020  2023\\n\\n</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145580</td>\n",
       "      <td>1.194438</td>\n",
       "      <td>0.539361</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Medium</td>\n",
       "      <td>High</td>\n",
       "      <td>2</td>\n",
       "      <td>1.286938</td>\n",
       "      <td>\\n137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>httpscdnsofifacomplayers21969321_60png</td>\n",
       "      <td>Diego Carlos Santos Silva</td>\n",
       "      <td>httpsofifacomplayer219693diegocarlossantossilv...</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>CB</td>\n",
       "      <td>Diego Carlos</td>\n",
       "      <td>0.473714</td>\n",
       "      <td>2.695886</td>\n",
       "      <td>2.339230</td>\n",
       "      <td>\\n\\n\\n\\nSevilla FC\\n2019  2024\\n\\n</td>\n",
       "      <td>...</td>\n",
       "      <td>1.189752</td>\n",
       "      <td>-1.153433</td>\n",
       "      <td>0.202739</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Medium</td>\n",
       "      <td>High</td>\n",
       "      <td>2</td>\n",
       "      <td>2.078310</td>\n",
       "      <td>\\n170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>httpscdnsofifacomplayers21533321_60png</td>\n",
       "      <td>Duván Zapata</td>\n",
       "      <td>httpsofifacomplayer215333duvanzapata210005</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>ST</td>\n",
       "      <td>D Zapata</td>\n",
       "      <td>0.940828</td>\n",
       "      <td>2.695886</td>\n",
       "      <td>1.991996</td>\n",
       "      <td>\\n\\n\\n\\nAtalanta\\n2020  2023\\n\\n</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.813247</td>\n",
       "      <td>-1.488843</td>\n",
       "      <td>-0.807126</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>High</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2</td>\n",
       "      <td>2.078310</td>\n",
       "      <td>\\n123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>httpscdnsofifacomplayers21051421_60png</td>\n",
       "      <td>João Pedro Cavaco Cancelo</td>\n",
       "      <td>httpsofifacomplayer210514joaopedrocavacocancel...</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>RB</td>\n",
       "      <td>João Cancelo</td>\n",
       "      <td>0.240157</td>\n",
       "      <td>2.695886</td>\n",
       "      <td>2.512848</td>\n",
       "      <td>\\n\\n\\n\\nManchester City\\n2019  2025\\n\\n</td>\n",
       "      <td>...</td>\n",
       "      <td>1.523585</td>\n",
       "      <td>1.194438</td>\n",
       "      <td>1.212604</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>High</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2</td>\n",
       "      <td>0.608619</td>\n",
       "      <td>\\n117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18945</th>\n",
       "      <td>httpscdnsofifacomplayers25255621_60png</td>\n",
       "      <td>Brendon Shabani</td>\n",
       "      <td>httpsofifacomplayer252556brendonshabani210005</td>\n",
       "      <td>Albania</td>\n",
       "      <td>CM</td>\n",
       "      <td>B Shabani</td>\n",
       "      <td>-1.628302</td>\n",
       "      <td>-2.942721</td>\n",
       "      <td>-0.612262</td>\n",
       "      <td>\\n\\n\\n\\nLeyton Orient\\n2019  2021\\n\\n</td>\n",
       "      <td>...</td>\n",
       "      <td>1.523585</td>\n",
       "      <td>1.194438</td>\n",
       "      <td>0.875983</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.765497</td>\n",
       "      <td>\\n5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18950</th>\n",
       "      <td>httpscdnsofifacomplayers24772021_60png</td>\n",
       "      <td>Chaoyang Liu</td>\n",
       "      <td>httpsofifacomplayer247720chaoyangliu210005</td>\n",
       "      <td>China PR</td>\n",
       "      <td>CM</td>\n",
       "      <td>Liu Chaoyang</td>\n",
       "      <td>-0.927630</td>\n",
       "      <td>-2.942721</td>\n",
       "      <td>-2.001199</td>\n",
       "      <td>\\n\\n\\n\\nShandong Luneng TaiShan FC\\n2019  2022...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.189752</td>\n",
       "      <td>0.859028</td>\n",
       "      <td>0.202739</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.974125</td>\n",
       "      <td>\\n2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18959</th>\n",
       "      <td>httpscdnsofifacomplayers25826821_60png</td>\n",
       "      <td>Ethan Espinoza</td>\n",
       "      <td>httpsofifacomplayer258268ethanespinoza210005</td>\n",
       "      <td>Chile</td>\n",
       "      <td>CM</td>\n",
       "      <td>E Espinoza</td>\n",
       "      <td>-1.394745</td>\n",
       "      <td>-2.942721</td>\n",
       "      <td>-1.827582</td>\n",
       "      <td>\\n\\n\\n\\nColoColo\\n2020  2024\\n\\n</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145580</td>\n",
       "      <td>1.194438</td>\n",
       "      <td>1.549226</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.748019</td>\n",
       "      <td>\\n2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18960</th>\n",
       "      <td>httpscdnsofifacomplayers25111021_60png</td>\n",
       "      <td>Haijian Wang</td>\n",
       "      <td>httpsofifacomplayer251110haijianwang210005</td>\n",
       "      <td>China PR</td>\n",
       "      <td>CM</td>\n",
       "      <td>Wang Haijian</td>\n",
       "      <td>-1.394745</td>\n",
       "      <td>-2.942721</td>\n",
       "      <td>-2.522051</td>\n",
       "      <td>\\n\\n\\n\\nShanghai Greenland Shenhua FC\\n2019  2...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855919</td>\n",
       "      <td>0.859028</td>\n",
       "      <td>0.875983</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.313285</td>\n",
       "      <td>\\n1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18962</th>\n",
       "      <td>httpscdnsofifacomplayers25316821_60png</td>\n",
       "      <td>Jack Smith</td>\n",
       "      <td>httpsofifacomplayer253168jacksmith210005</td>\n",
       "      <td>England</td>\n",
       "      <td>CM</td>\n",
       "      <td>J Smith</td>\n",
       "      <td>-1.628302</td>\n",
       "      <td>-2.942721</td>\n",
       "      <td>-1.480348</td>\n",
       "      <td>\\n\\n\\n\\nStevenage\\n2019  2021\\n\\n</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.147080</td>\n",
       "      <td>0.859028</td>\n",
       "      <td>-0.807126</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1</td>\n",
       "      <td>0.269460</td>\n",
       "      <td>\\n1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12564 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     photourl                       longname  \\\n",
       "146    httpscdnsofifacomplayers23048121_60png  Ronaldo Jailson Cabrais Petri   \n",
       "150    httpscdnsofifacomplayers22792821_60png           Nélson Cabral Semedo   \n",
       "158    httpscdnsofifacomplayers21969321_60png      Diego Carlos Santos Silva   \n",
       "161    httpscdnsofifacomplayers21533321_60png                   Duván Zapata   \n",
       "165    httpscdnsofifacomplayers21051421_60png      João Pedro Cavaco Cancelo   \n",
       "...                                       ...                            ...   \n",
       "18945  httpscdnsofifacomplayers25255621_60png                Brendon Shabani   \n",
       "18950  httpscdnsofifacomplayers24772021_60png                   Chaoyang Liu   \n",
       "18959  httpscdnsofifacomplayers25826821_60png                 Ethan Espinoza   \n",
       "18960  httpscdnsofifacomplayers25111021_60png                   Haijian Wang   \n",
       "18962  httpscdnsofifacomplayers25316821_60png                     Jack Smith   \n",
       "\n",
       "                                               playerurl nationality  \\\n",
       "146    httpsofifacomplayer230481ronaldojailsoncabrais...      Brazil   \n",
       "150    httpsofifacomplayer227928nelsoncabralsemedo210005    Portugal   \n",
       "158    httpsofifacomplayer219693diegocarlossantossilv...      Brazil   \n",
       "161           httpsofifacomplayer215333duvanzapata210005    Colombia   \n",
       "165    httpsofifacomplayer210514joaopedrocavacocancel...    Portugal   \n",
       "...                                                  ...         ...   \n",
       "18945      httpsofifacomplayer252556brendonshabani210005     Albania   \n",
       "18950         httpsofifacomplayer247720chaoyangliu210005    China PR   \n",
       "18959       httpsofifacomplayer258268ethanespinoza210005       Chile   \n",
       "18960         httpsofifacomplayer251110haijianwang210005    China PR   \n",
       "18962           httpsofifacomplayer253168jacksmith210005     England   \n",
       "\n",
       "      positions             name       age      ↓ova       pot  \\\n",
       "146      CAM RM  Ronaldo Cabrais  0.707271  2.695886  1.991996   \n",
       "150          RB    Nélson Semedo  0.240157  2.695886  2.512848   \n",
       "158          CB     Diego Carlos  0.473714  2.695886  2.339230   \n",
       "161          ST         D Zapata  0.940828  2.695886  1.991996   \n",
       "165          RB     João Cancelo  0.240157  2.695886  2.512848   \n",
       "...         ...              ...       ...       ...       ...   \n",
       "18945        CM        B Shabani -1.628302 -2.942721 -0.612262   \n",
       "18950        CM     Liu Chaoyang -0.927630 -2.942721 -2.001199   \n",
       "18959        CM       E Espinoza -1.394745 -2.942721 -1.827582   \n",
       "18960        CM     Wang Haijian -1.394745 -2.942721 -2.522051   \n",
       "18962        CM          J Smith -1.628302 -2.942721 -1.480348   \n",
       "\n",
       "                                         team & contract  ...  gk kicking  \\\n",
       "146                       \\n\\n\\n\\nGrêmio\\n2019  2023\\n\\n  ...    0.855919   \n",
       "150      \\n\\n\\n\\nWolverhampton Wanderers\\n2020  2023\\n\\n  ...   -0.145580   \n",
       "158                   \\n\\n\\n\\nSevilla FC\\n2019  2024\\n\\n  ...    1.189752   \n",
       "161                     \\n\\n\\n\\nAtalanta\\n2020  2023\\n\\n  ...   -0.813247   \n",
       "165              \\n\\n\\n\\nManchester City\\n2019  2025\\n\\n  ...    1.523585   \n",
       "...                                                  ...  ...         ...   \n",
       "18945              \\n\\n\\n\\nLeyton Orient\\n2019  2021\\n\\n  ...    1.523585   \n",
       "18950  \\n\\n\\n\\nShandong Luneng TaiShan FC\\n2019  2022...  ...    1.189752   \n",
       "18959                   \\n\\n\\n\\nColoColo\\n2020  2024\\n\\n  ...   -0.145580   \n",
       "18960  \\n\\n\\n\\nShanghai Greenland Shenhua FC\\n2019  2...  ...    0.855919   \n",
       "18962                  \\n\\n\\n\\nStevenage\\n2019  2021\\n\\n  ...   -1.147080   \n",
       "\n",
       "      gk positioning gk reflexes w/f sm     a/w     d/w  ir       phy   hits  \n",
       "146         1.529848    0.875983  4   4  Medium     Low  1   0.834725   \\n46  \n",
       "150         1.194438    0.539361  3   4  Medium    High  2   1.286938  \\n137  \n",
       "158        -1.153433    0.202739  4   3  Medium    High  2   2.078310  \\n170  \n",
       "161        -1.488843   -0.807126  4   3    High  Medium  2   2.078310  \\n123  \n",
       "165         1.194438    1.212604  3   4    High  Medium  2   0.608619  \\n117  \n",
       "...              ...         ...  .. ..     ...     ...  ..       ...    ...  \n",
       "18945       1.194438    0.875983  3   2  Medium  Medium  1  -1.765497    \\n5  \n",
       "18950       0.859028    0.202739  3   2  Medium  Medium  1  -0.974125    \\n2  \n",
       "18959       1.194438    1.549226  2   2  Medium  Medium  1  -0.748019    \\n2  \n",
       "18960       0.859028    0.875983  2   2  Medium  Medium  1  -1.313285    \\n1  \n",
       "18962       0.859028   -0.807126  3   2  Medium  Medium  1   0.269460    \\n1  \n",
       "\n",
       "[12564 rows x 65 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_standardized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
